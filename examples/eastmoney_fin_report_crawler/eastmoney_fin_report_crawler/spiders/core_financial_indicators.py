# -*- coding: UTF-8 -*-
"""
financial_reports_spider.spiders.core_financial_indicators
=======================================
ç”± `crawlo genspider` å‘½ä»¤ç”Ÿæˆçš„çˆ¬è™«ã€‚
åŸºäº Crawlo æ¡†æ¶ï¼Œæ”¯æŒå¼‚æ­¥å¹¶å‘ã€åˆ†å¸ƒå¼çˆ¬å–ç­‰åŠŸèƒ½ã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š
    crawlo crawl core_financial_indicators
"""

from crawlo.spider import Spider
from crawlo import Request

from utils.tools import generate_pmid, get_v_params, round_if_numeric
from ..items import CoreFinancialIndicatorsItem
from ..settings import HEADERS, STOCKS, REPORT_DATE_FILTER
from data.field_mapping import CORE_FIELD_MAPPING


class CoreFinancialIndicatorsSpider(Spider):
    """
    çˆ¬è™«ï¼šcore_financial_indicators ä¸»è¦æŒ‡æ ‡

    åŠŸèƒ½è¯´æ˜ï¼š
    - æ”¯æŒå¹¶å‘çˆ¬å–
    - è‡ªåŠ¨å»é‡è¿‡æ»¤
    - é”™è¯¯é‡è¯•æœºåˆ¶ï¼ˆå«ä¸šåŠ¡é”™è¯¯é‡è¯•ï¼‰
    - å¤±è´¥è‚¡ç¥¨æ”¶é›†ä¸æŠ¥å‘Š
    - æ•°æ®ç®¡é“å¤„ç†
    """
    name = 'core_financial_indicators'
    allowed_domains = ['datacenter.eastmoney.com', 'datapc.eastmoney.com']
    # start_urls = STOCKS

    # é«˜çº§é…ç½®ï¼ˆå¯é€‰ï¼‰
    custom_settings = {
        "DOWNLOAD_DELAY": 5,
        "MYSQL_TABLE": "listed_finance_and_taxation_report",
    }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.failed_stocks = set()  # ç”¨äºæ”¶é›†æœ€ç»ˆå¤±è´¥çš„è‚¡ç¥¨ä»£ç 

    def start_requests(self):
        """
        ç”Ÿæˆåˆå§‹è¯·æ±‚ã€‚
        """
        url = "https://datacenter.eastmoney.com/securities/api/data/get"
        for stock_code in STOCKS:
            params = {
                "type": "RPT_F10_FINANCE_MAINFINADATA",
                "sty": "APP_F10_MAINFINADATA",
                "quoteColumns": "",
                "filter": f"(SECUCODE=\"{stock_code}\")",
                "p": "1",
                "ps": "200",
                "sr": "-1",
                "st": "REPORT_DATE",
                "source": "HSF10",
                "client": "PC",
                # "v": "0735573993472252"
            }
            v_value = get_v_params(params)
            params['v'] = v_value
            yield Request(
                url=url,
                callback=self.parse,
                headers=HEADERS,
                params=params,
                meta={'stock_code': stock_code}  # ğŸ‘ˆ ä¼ é€’è‚¡ç¥¨ä»£ç 
            )

    def parse(self, response):
        stock_code = response.meta.get('stock_code', 'UNKNOWN')
        retry_times = response.meta.get('retry_times', 0)
        max_retry_times = 3

        try:
            json_data = response.json()
            msg = json_data.get('message', '').strip()

            # æ£€æŸ¥ API æ˜¯å¦è¿”å›æˆåŠŸ
            if msg != 'ok':
                self.logger.warning(
                    f"è‚¡ç¥¨ {stock_code} API è¿”å›é 'ok' æ¶ˆæ¯: '{msg}' (é‡è¯• {retry_times}/{max_retry_times}), URL: {response.url}"
                )
                if retry_times < max_retry_times:
                    # é‡è¯•ï¼šå¤ç”¨åŸè¯·æ±‚ï¼Œå¢åŠ é‡è¯•æ¬¡æ•°
                    new_request = response.request.replace(
                        meta={
                            'stock_code': stock_code,
                            'retry_times': retry_times + 1
                        }
                    )
                    yield new_request
                else:
                    self.logger.error(f"è‚¡ç¥¨ {stock_code} è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ ‡è®°ä¸ºå¤±è´¥ã€‚æœ€ç»ˆæ¶ˆæ¯: {msg}")
                    self.failed_stocks.add(stock_code)
                return

            rows = json_data.get('result', {}).get('data', [])
            if not rows:
                self.logger.info(f"è‚¡ç¥¨ {stock_code} æ— ä¸»è¦è´¢åŠ¡æŒ‡æ ‡æ•°æ®è¿”å›")
                # æ³¨æ„ï¼šè¿™é‡Œä¸è§†ä¸ºâ€œå¤±è´¥â€ï¼Œå› ä¸ºå¯èƒ½æ˜¯æ­£å¸¸æ— æ•°æ®ï¼ˆå¦‚æ–°ä¸Šå¸‚ï¼‰
                # å¦‚æœä¸šåŠ¡ä¸Šè®¤ä¸ºâ€œå¿…é¡»æœ‰æ•°æ®â€ï¼Œåˆ™å–æ¶ˆä¸‹é¢æ³¨é‡Šï¼š
                # self.failed_stocks.add(stock_code)
                return

            for idx, row in enumerate(rows, 1):
                try:
                    item = CoreFinancialIndicatorsItem()
                    for field_name, original_key in CORE_FIELD_MAPPING.items():
                        # item[field_name] = row.get(original_key)
                        raw_value = row.get(original_key)
                        item[field_name] = round_if_numeric(raw_value, decimal_places=4)

                    stock_code_item = item.get('stock_code')
                    report_date = item.get('report_date')

                    if not stock_code_item or not report_date:
                        self.logger.warning(
                            f"è‚¡ç¥¨ {stock_code} ç¬¬ {idx} æ¡æ•°æ®ç¼ºå¤±å…³é”®å­—æ®µï¼Œè·³è¿‡ - stock_code: {stock_code_item}, report_date: {report_date}"
                        )
                        continue

                    # æ£€æŸ¥æŠ¥å‘ŠæœŸæ˜¯å¦ä¸ºæŒ‡å®šæ—¥æœŸ
                    if report_date != REPORT_DATE_FILTER:
                        self.logger.info(
                            f"è‚¡ç¥¨ {stock_code} ç¬¬ {idx} æ¡æ•°æ®æŠ¥å‘ŠæœŸä¸ç¬¦åˆè¦æ±‚ï¼Œè·³è¿‡ - stock_code: {stock_code_item}, report_date: {report_date}"
                        )
                        continue  # è·³è¿‡ä¸ç¬¦åˆæŠ¥å‘ŠæœŸè¦æ±‚çš„æ•°æ®

                    item['pmid'] = generate_pmid(stock_code=stock_code_item, report_date=report_date)
                    yield item

                except Exception as row_e:
                    self.logger.error(
                        f"å¤„ç†è‚¡ç¥¨ {stock_code} ç¬¬ {idx} æ¡æ•°æ®å¤±è´¥: {row_e}, æ•°æ®: {row}",
                        exc_info=True
                    )
                    continue

        except Exception as e:
            self.logger.error(
                f"âŒ è‚¡ç¥¨ {stock_code} å“åº”è§£æå¤±è´¥ - çŠ¶æ€ç : {response.status_code}, URL: {response.url}, é”™è¯¯: {e}",
                exc_info=True
            )
            if retry_times < max_retry_times:
                yield response.request.replace(
                    meta={
                        'stock_code': stock_code,
                        'retry_times': retry_times + 1
                    }
                )
            else:
                self.failed_stocks.add(stock_code)

    def close(self, reason):
        """
        çˆ¬è™«å…³é—­æ—¶è°ƒç”¨ï¼Œè¾“å‡ºå¤±è´¥è‚¡ç¥¨åˆ—è¡¨
        """
        if self.failed_stocks:
            self.logger.info("=" * 60)
            self.logger.info("âŒ ä»¥ä¸‹è‚¡ç¥¨çš„ä¸»è¦è´¢åŠ¡æŒ‡æ ‡é‡‡é›†å¤±è´¥ï¼ˆå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼‰:")
            for stock in sorted(self.failed_stocks):
                self.logger.info(f"  - {stock}")
            self.logger.info(f"æ€»è®¡å¤±è´¥è‚¡ç¥¨æ•°é‡: {len(self.failed_stocks)}")
            self.logger.info("=" * 60)

            # ä¿å­˜åˆ°æ–‡ä»¶
            with open('failed_core_financial_stocks.txt', 'w', encoding='utf-8') as f:
                for stock in sorted(self.failed_stocks):
                    f.write(stock + '\n')
            self.logger.info("å¤±è´¥è‚¡ç¥¨åˆ—è¡¨å·²ä¿å­˜è‡³: failed_core_financial_stocks.txt")
        else:
            self.logger.info("âœ… æ‰€æœ‰è‚¡ç¥¨çš„ä¸»è¦è´¢åŠ¡æŒ‡æ ‡æ•°æ®é‡‡é›†æˆåŠŸï¼")
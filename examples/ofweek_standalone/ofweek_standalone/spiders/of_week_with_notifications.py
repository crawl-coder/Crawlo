# -*- coding: utf-8 -*-
"""
===================================
é›†æˆé€šçŸ¥åŠŸèƒ½çš„ ofweek çˆ¬è™«ç¤ºä¾‹
===================================

å±•ç¤ºå¦‚ä½•åœ¨å®é™…çˆ¬è™«ä¸­é›†æˆ Crawlo é€šçŸ¥ç³»ç»Ÿ
"""
import time
import asyncio
import random
from crawlo.spider import Spider
from crawlo import Request, Response
from ..items import OfWeekStandaloneItem
from crawlo.bot.models import ChannelType
from crawlo.bot.handlers import send_crawler_status
from crawlo.bot import (
    send_template_notification, 
    Template,
    get_template_parameters,
    render_resource_monitor_template,
    ResourceTemplate,
    send_crawler_alert
)



class OfWeekSpiderWithNotifications(Spider):
    """é›†æˆé€šçŸ¥åŠŸèƒ½çš„ ofweek çˆ¬è™«"""
    
    name = 'of_week_with_notifications'
    allowed_domains = ['ee.ofweek.com']
    start_urls = ['https://ee.ofweek.com/']
    custom_settings = {}
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.stats = {
            'total_requests': 0,
            'successful_items': 0,
            'failed_requests': 0,
            'start_time': None
        }
    
    def start_requests(self):
        """ç”Ÿæˆåˆå§‹è¯·æ±‚ - å¸¦å¯åŠ¨é€šçŸ¥"""
        # ä½¿ç”¨æ¨¡æ¿å‘é€çˆ¬è™«å¯åŠ¨é€šçŸ¥
        response = send_template_notification(
            Template.task_startup,
            task_name='ofweekçˆ¬è™«',
            target='OFweekç”µå­å·¥ç¨‹ç½‘',
            estimated_time='5-10åˆ†é’Ÿ',
            channel=ChannelType.DINGTALK
        )
        if not response.success:
            self.logger.warning(f"å‘é€å¯åŠ¨é€šçŸ¥å¤±è´¥: {response.message}")
        
        # å‘é€ç³»ç»Ÿèµ„æºç›‘æ§é€šçŸ¥ï¼ˆæ¨¡æ‹Ÿï¼‰
        resource_response = send_template_notification(
            Template.resource_monitor,
            memory_usage='65',
            cpu_usage='45',
            disk_usage='30',
            active_connections='45',
            channel=ChannelType.DINGTALK
        )
        
        # æµ‹è¯•èµ„æºç›‘æ§æ¨¡æ¿ - MySQLè¿æ¥æ± ç›‘æ§
        mysql_monitor_response = send_template_notification(
            Template.task_startup,  # ä½¿ç”¨é€šç”¨æ¨¡æ¿ï¼Œä½†ä¼ é€’MySQLç›‘æ§å‚æ•°
            task_name='MySQLè¿æ¥æ± ç›‘æ§',
            target='MySQLæ•°æ®åº“',
            estimated_time='æŒç»­ç›‘æ§',
            channel=ChannelType.DINGTALK
        )
        
        # æµ‹è¯•ä¼˜åŒ–åçš„é€šçŸ¥æ ¼å¼
        try:
            # å‘é€ä»»åŠ¡å¯åŠ¨é€šçŸ¥ï¼ˆæµ‹è¯•ç®€åŒ–æ ¼å¼ï¼‰
            startup_result = send_template_notification(
                Template.task_startup,
                task_name='ofweekçˆ¬è™«',
                target='OFweekç”µå­å·¥ç¨‹ç½‘',
                estimated_time='5-10åˆ†é’Ÿ',
                channel=ChannelType.DINGTALK
            )
            self.logger.info(f"ğŸš€ ä»»åŠ¡å¯åŠ¨é€šçŸ¥: {startup_result.message}")
            
            # å‘é€è¿›åº¦é€šçŸ¥
            progress_result = send_template_notification(
                Template.task_progress,
                task_name='ofweekçˆ¬è™«',
                percentage='10',
                current_count=5,
                channel=ChannelType.DINGTALK
            )
            self.logger.info(f"ğŸ“Š è¿›åº¦é€šçŸ¥: {progress_result.message}")
            
            # å‘é€å‘Šè­¦é€šçŸ¥
            alert_result = send_template_notification(
                Template.error_alert,
                task_name='ofweekçˆ¬è™«',
                error_message='æµ‹è¯•å‘Šè­¦æ¶ˆæ¯',
                error_time=time.strftime('%Y-%m-%d %H:%M:%S'),
                channel=ChannelType.DINGTALK
            )
            self.logger.info(f"ğŸš¨ å‘Šè­¦é€šçŸ¥: {alert_result.message}")
            
        except Exception as e:
            self.logger.warning(f"å‘é€æµ‹è¯•é€šçŸ¥å¤±è´¥: {e}")
        
        # æµ‹è¯•èµ„æºç›‘æ§æ¨¡æ¿ - ä½¿ç”¨ä¸“ç”¨èµ„æºç›‘æ§æ¨¡æ¿
        try:
            from crawlo.bot import render_resource_monitor_template, ResourceTemplate
            mysql_monitor_result = render_resource_monitor_template(
                ResourceTemplate.MYSQL_CONNECTION_POOL_MONITOR.value,
                pool_status="æ­£å¸¸",
                active_connections=15,
                idle_connections=5,
                max_connections=50,
                waiting_connections=0,
                timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
            )
            if mysql_monitor_result:
                send_crawler_status(
                    title=mysql_monitor_result['title'],
                    content=mysql_monitor_result['content'],
                    channel=ChannelType.DINGTALK
                )
        except Exception as e:
            self.logger.warning(f"å‘é€MySQLç›‘æ§é€šçŸ¥å¤±è´¥: {e}")
        
        # æµ‹è¯•èµ„æºç›‘æ§æ¨¡æ¿ - Rediså†…å­˜ç›‘æ§
        try:
            redis_monitor_result = render_resource_monitor_template(
                ResourceTemplate.REDIS_MEMORY_MONITOR.value,
                used_memory="2.5GB",
                max_memory="4GB",
                memory_usage_percent=62.5,
                memory_fragmentation_ratio=1.2,
                hit_rate=98.5,
                timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
            )
            if redis_monitor_result:
                send_crawler_status(
                    title=redis_monitor_result['title'],
                    content=redis_monitor_result['content'],
                    channel=ChannelType.DINGTALK
                )
        except Exception as e:
            self.logger.warning(f"å‘é€Redisç›‘æ§é€šçŸ¥å¤±è´¥: {e}")
        
        # æµ‹è¯•æ¶ˆæ¯å»é‡åŠŸèƒ½ - å‘é€ç›¸åŒçš„æ¶ˆæ¯ä¸¤æ¬¡ï¼Œç¬¬äºŒæ¬¡åº”è¯¥è¢«å»é‡
        duplicate_test_response1 = send_template_notification(
            Template.task_startup,
            task_name='å»é‡æµ‹è¯•ä»»åŠ¡',
            target='æµ‹è¯•ç½‘ç«™',
            estimated_time='1åˆ†é’Ÿ',
            channel=ChannelType.DINGTALK
        )
        self.logger.info(f"ç¬¬ä¸€æ¬¡å»é‡æµ‹è¯•ç»“æœ: {duplicate_test_response1.message}")
        
        # ç«‹å³å‘é€ç›¸åŒçš„æ¶ˆæ¯ï¼Œåº”è¯¥è¢«å»é‡æœºåˆ¶æ‹¦æˆª
        duplicate_test_response2 = send_template_notification(
            Template.task_startup,
            task_name='å»é‡æµ‹è¯•ä»»åŠ¡',
            target='æµ‹è¯•ç½‘ç«™',
            estimated_time='1åˆ†é’Ÿ',
            channel=ChannelType.DINGTALK
        )
        self.logger.info(f"ç¬¬äºŒæ¬¡å»é‡æµ‹è¯•ç»“æœ: {duplicate_test_response2.message}")
        
        # æµ‹è¯•æŸ¥è¯¢æ¨¡æ¿å‚æ•°åŠŸèƒ½
        try:
            startup_params = get_template_parameters(Template.task_startup)
            self.logger.info(f"task_startupæ¨¡æ¿å‚æ•°: {startup_params}")
        except Exception as e:
            self.logger.warning(f"æŸ¥è¯¢æ¨¡æ¿å‚æ•°å¤±è´¥: {e}")
        
        self.stats['start_time'] = self.get_current_time()
        self.logger.info("çˆ¬è™«å¯åŠ¨é€šçŸ¥å·²å‘é€")
        
        # åŸæœ‰çš„èµ·å§‹è¯·æ±‚é€»è¾‘
        max_pages = 2
        start_urls = []
        for page in range(1, max_pages + 1):
            url = f'https://ee.ofweek.com/CATList-2800-8100-ee-{page}.html'
            start_urls.append(url)
        
        self.logger.info(f"ç”Ÿæˆäº† {len(start_urls)} ä¸ªèµ·å§‹URL")
        
        for url in start_urls:
            self.stats['total_requests'] += 1
            yield Request(url, callback=self.parse, dont_filter=True)
    
    async def parse(self, response: Response):
        """è§£æå“åº” - å¸¦è¿›åº¦å’Œå¼‚å¸¸é€šçŸ¥"""
        try:
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                self.stats['failed_requests'] += 1
                error_msg = f"é¡µé¢è¿”å›é200çŠ¶æ€ç : {response.status_code}"
                self.logger.warning(f"{error_msg}, URL: {response.url}")
                
                # ä¿å­˜åŸå§‹å“åº”ä¿¡æ¯
                original_url = response.url
                original_status = response.status_code
                
                # å‘é€HTTPé”™è¯¯é€šçŸ¥ï¼ˆæ¯10æ¬¡é”™è¯¯å‘é€ä¸€æ¬¡ï¼Œé¿å…è¿‡äºé¢‘ç¹ï¼‰
                if self.stats['failed_requests'] % 10 == 1:
                    http_error_response = send_template_notification(
                        Template.http_error,
                        status_code=original_status,
                        url=original_url,
                        response_time='2500',
                        retry_count='3',
                        channel=ChannelType.DINGTALK
                    )
                
                    if not http_error_response.success:
                        self.logger.warning(f"å‘é€HTTPé”™è¯¯é€šçŸ¥å¤±è´¥: {http_error_response.message}")
                        
                    # åŒæ—¶å‘é€èµ„æºç›‘æ§æ¨¡æ¿ä¸­çš„é”™è¯¯ç›¸å…³æ¨¡æ¿
                    try:
                        mysql_slow_query_result = render_resource_monitor_template(
                            ResourceTemplate.MYSQL_SLOW_QUERY_ALERT.value,
                            sql_statement=f"SELECT * FROM pages WHERE url = '{original_url}'",
                            execution_time=2.5,
                            affected_rows=1,
                            target_table="pages",
                            query_source="ofweek_spider"
                        )
                        if mysql_slow_query_result:
                            send_crawler_alert(
                                title=mysql_slow_query_result['title'],
                                content=mysql_slow_query_result['content'],
                                channel=ChannelType.DINGTALK
                            )
                    except Exception as e:
                        self.logger.warning(f"å‘é€MySQLæ…¢æŸ¥è¯¢å‘Šè­¦å¤±è´¥: {e}")
                return
            
            # æ£€æŸ¥é¡µé¢å†…å®¹æ˜¯å¦ä¸ºç©º
            if not response.text or len(response.text.strip()) == 0:
                self.stats['failed_requests'] += 1
                self.logger.warning(f"é¡µé¢å†…å®¹ä¸ºç©º: {response.url}")
                
                # å‘é€è§£æå¤±è´¥é€šçŸ¥ï¼ˆæ¯10æ¬¡é”™è¯¯å‘é€ä¸€æ¬¡ï¼‰
                if self.stats['failed_requests'] % 10 == 1:
                    parse_error_response = send_template_notification(
                        Template.parse_failure,
                        parse_success='å¦',
                        data_count='0',
                        error_type='å†…å®¹ä¸ºç©º',
                        url=response.url,
                        channel=ChannelType.DINGTALK
                    )
                    
                    # åŒæ—¶å‘é€MongoDBç›‘æ§æ¨¡æ¿ï¼ˆæ¨¡æ‹Ÿæ•°æ®åº“æ“ä½œï¼‰
                    try:
                        mongodb_result = render_resource_monitor_template(
                            ResourceTemplate.MONGODB_SLOW_OPERATION_ALERT.value,
                            operation_type="find",
                            execution_time=1.8,
                            collection_name="pages",
                            documents_affected=0,
                            operation_source="ofweek_spider"
                        )
                        if mongodb_result:
                            send_crawler_alert(
                                title=mongodb_result['title'],
                                content=mongodb_result['content'],
                                channel=ChannelType.DINGTALK
                            )
                    except Exception as e:
                        self.logger.warning(f"å‘é€MongoDBæ…¢æ“ä½œå‘Šè­¦å¤±è´¥: {e}")
                return
            
            # éšæœºæ¨¡æ‹ŸéªŒè¯ç æ£€æµ‹ï¼ˆé™ä½é¢‘ç‡ï¼‰
            if random.random() < 0.01:  # 1%æ¦‚ç‡
                captcha_response = send_template_notification(
                    Template.captcha_detected,
                    captcha_status='æ£€æµ‹åˆ°',
                    url=response.url,
                    user_agent='Mozilla/5.0',
                    error_time=self.get_current_time_str(),
                    channel=ChannelType.DINGTALK
                )
                
                # å‘é€å®‰å…¨å‘Šè­¦
                security_response = send_template_notification(
                    Template.security_alert,
                    security_alert='éªŒè¯ç æ£€æµ‹',
                    auth_status='æ­£å¸¸',
                    access_denied='å¦',
                    error_time=self.get_current_time_str(),
                    channel=ChannelType.DINGTALK
                )

            # æ•°æ®æå–
            rows = response.xpath('//div[@class="main_left"]/div[@class="list_model"]/div[@class="model_right model_right2"]')
            self.logger.info(f"åœ¨é¡µé¢ {response.url} ä¸­æ‰¾åˆ° {len(rows)} ä¸ªæ¡ç›®")
            
            # å‘é€è¿›åº¦é€šçŸ¥ï¼ˆæ¯å¤„ç†10ä¸ªé¡µé¢å‘é€ä¸€æ¬¡ï¼Œé¿å…è¿‡äºé¢‘ç¹ï¼‰
            if self.stats['total_requests'] % 10 == 0:
                progress_response = send_template_notification(
                    Template.task_progress,
                    task_name='ofweekçˆ¬è™«',
                    percentage=f"{min(100, (self.stats['total_requests'] / 20) * 100):.1f}",
                    current_count=self.stats['total_requests'],
                    channel=ChannelType.DINGTALK
                )
                if not progress_response.success:
                    self.logger.warning(f"å‘é€è¿›åº¦é€šçŸ¥å¤±è´¥: {progress_response.message}")
                
                # åŒæ—¶å‘é€Redisè¿æ¥ç›‘æ§
                try:
                    redis_conn_result = render_resource_monitor_template(
                        ResourceTemplate.REDIS_CONNECTION_MONITOR.value,
                        connection_status="å¥åº·",
                        connected_clients=120,
                        max_clients=1000,
                        input_kbps=1024,
                        output_kbps=2048,
                        timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
                    )
                    if redis_conn_result:
                        send_crawler_status(
                            title=redis_conn_result['title'],
                            content=redis_conn_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as e:
                    self.logger.warning(f"å‘é€Redisè¿æ¥ç›‘æ§å¤±è´¥: {e}")
            
            for row in rows:
                try:
                    # æå–URLå’Œæ ‡é¢˜
                    url = row.xpath('./h3/a/@href').extract_first()
                    title = row.xpath('./h3/a/text()').extract_first()
                    
                    # å®¹é”™å¤„ç†
                    if not url or not title:
                        continue
                    
                    # ç¡®ä¿ URL æ˜¯ç»å¯¹è·¯å¾„
                    absolute_url = response.urljoin(url)
                    
                    # åˆ›å»ºè¯·æ±‚ - ä½¿ç”¨æ­£ç¡®çš„å‚æ•°
                    yield Request(
                        url=absolute_url,
                        callback=self.parse_detail,
                        err_back=self.handle_error,
                        meta={'title': title}
                    )
                    
                except Exception as e:
                    self.logger.error(f"å¤„ç†è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")
                    # å‘é€æ•°æ®å¤„ç†é”™è¯¯é€šçŸ¥ï¼ˆé™ä½é¢‘ç‡ï¼‰
                    if self.stats['failed_requests'] % 20 == 1:
                        data_error_response = send_template_notification(
                            Template.error_alert,
                            task_name='ofweekçˆ¬è™«',
                            error_message=f'æ•°æ®å¤„ç†é”™è¯¯: {str(e)}',
                            error_time=self.get_current_time_str(),
                            channel=ChannelType.DINGTALK
                        )
                        
                        # åŒæ—¶å‘é€é€šç”¨èµ„æºæ³„éœ²å‘Šè­¦
                        try:
                            general_leak_result = render_resource_monitor_template(
                                ResourceTemplate.GENERAL_RESOURCE_LEAK_ALERT.value,
                                resource_type="å†…å­˜",
                                leak_details=f"å¤„ç†æ•°æ®æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}",
                                growth_trend="å¼‚å¸¸å¢é•¿",
                                severity_level="é«˜",
                                discovery_time=time.strftime('%Y-%m-%d %H:%M:%S'),
                                affected_service="ofweek_spider"
                            )
                            if general_leak_result:
                                send_crawler_alert(
                                    title=general_leak_result['title'],
                                    content=general_leak_result['content'],
                                    channel=ChannelType.DINGTALK
                                )
                        except Exception as leak_e:
                            self.logger.warning(f"å‘é€èµ„æºæ³„éœ²å‘Šè­¦å¤±è´¥: {leak_e}")
        
        except Exception as e:
            self.stats['failed_requests'] += 1
            error_msg = f"è§£æé¡µé¢æ—¶å‘ç”Ÿå¼‚å¸¸: {e}"
            original_url = response.url
            
            # å‘é€ä¸¥é‡é”™è¯¯å‘Šè­¦ï¼ˆé™ä½é¢‘ç‡ï¼‰
            if self.stats['failed_requests'] % 5 == 1:
                severe_error_response = send_template_notification(
                    Template.error_alert,
                    task_name='ofweekçˆ¬è™«',
                    error_message=error_msg,
                    error_time=self.get_current_time_str(),
                    channel=ChannelType.DINGTALK
                )
                
                # å‘é€MySQLæ­»é”å‘Šè­¦ï¼ˆæ¨¡æ‹Ÿï¼‰
                try:
                    mysql_deadlock_result = render_resource_monitor_template(
                        ResourceTemplate.MYSQL_DEADLOCK_ALERT.value,
                        transaction_id="TXN_123456",
                        wait_time=30,
                        involved_transactions="2",
                        lock_type="è¡Œé”",
                        affected_table="pages"
                    )
                    if mysql_deadlock_result:
                        send_crawler_alert(
                            title=mysql_deadlock_result['title'],
                            content=mysql_deadlock_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as deadlock_e:
                    self.logger.warning(f"å‘é€MySQLæ­»é”å‘Šè­¦å¤±è´¥: {deadlock_e}")
                
                if not severe_error_response.success:
                    self.logger.warning(f"å‘é€ä¸¥é‡é”™è¯¯é€šçŸ¥å¤±è´¥: {severe_error_response.message}")
    
    async def parse_detail(self, response):
        """è§£æè¯¦æƒ…é¡µé¢ - å¸¦æ•°æ®ç»Ÿè®¡é€šçŸ¥"""
        try:
            self.logger.info(f'æ­£åœ¨è§£æè¯¦æƒ…é¡µ: {response.url}')
            
            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                self.stats['failed_requests'] += 1
                self.logger.warning(f"è¯¦æƒ…é¡µè¿”å›é200çŠ¶æ€ç : {response.status_code}")
                
                # å‘é€HTTPé”™è¯¯é€šçŸ¥ï¼ˆé™ä½é¢‘ç‡ï¼‰
                if self.stats['failed_requests'] % 5 == 1:
                    http_error_response = send_template_notification(
                        Template.http_error,
                        status_code=response.status_code,
                        url=response.url,
                        response_time='1800',
                        retry_count='1',
                        channel=ChannelType.DINGTALK
                    )
                    
                    # åŒæ—¶å‘é€Redis Keyè¿‡æœŸç›‘æ§ï¼ˆæ¨¡æ‹Ÿç¼“å­˜ç›¸å…³é”™è¯¯ï¼‰
                    try:
                        redis_ttl_result = render_resource_monitor_template(
                            ResourceTemplate.REDIS_KEY_TTL_MONITOR.value,
                            key_name=f"page_cache:{response.url}",
                            ttl_seconds=0,
                            business_type="é¡µé¢ç¼“å­˜",
                            key_size_bytes=1024,
                            storage_location="Redisé›†ç¾¤A"
                        )
                        if redis_ttl_result:
                            send_crawler_alert(
                                title=redis_ttl_result['title'],
                                content=redis_ttl_result['content'],
                                channel=ChannelType.DINGTALK
                            )
                    except Exception as e:
                        self.logger.warning(f"å‘é€Redis Keyè¿‡æœŸç›‘æ§å¤±è´¥: {e}")
                return
            
            title = response.meta.get('title', '')
            
            # æå–å†…å®¹
            content_elements = response.xpath('//div[@class="TRS_Editor"]|//*[@id="articleC"]')
            if content_elements:
                content = content_elements.xpath('.//text()').extract()
                content = '\n'.join([text.strip() for text in content if text.strip()])
            else:
                content = ''
            
            # æå–å‘å¸ƒæ—¶é—´å’Œæ¥æº
            publish_time = response.xpath('//div[@class="time fl"]/text()').extract_first()
            source = response.xpath('//div[@class="source-name"]/text()').extract_first()
            
            # åˆ›å»ºæ•°æ®é¡¹
            item = OfWeekStandaloneItem()
            item['title'] = title.strip() if title else ''
            item['publish_time'] = publish_time.strip() if publish_time else ''
            item['url'] = response.url
            item['source'] = source.strip() if source else ''
            item['content'] = content
            
            self.stats['successful_items'] += 1
            
            # æ¯æˆåŠŸå¤„ç†100æ¡æ•°æ®å‘é€ä¸€æ¬¡è¿›åº¦é€šçŸ¥
            if self.stats['successful_items'] % 100 == 0:
                progress_response = send_template_notification(
                    Template.task_progress,
                    task_name='ofweekçˆ¬è™«',
                    percentage=f"{min(100, (self.stats['successful_items'] / 500) * 100):.1f}",
                    current_count=self.stats['successful_items'],
                    channel=ChannelType.DINGTALK
                )
                if not progress_response.success:
                    self.logger.warning(f"å‘é€æ•°æ®ç»Ÿè®¡é€šçŸ¥å¤±è´¥: {progress_response.message}")
                
                # åŒæ—¶å‘é€MongoDBè¿æ¥ç›‘æ§
                try:
                    mongodb_conn_result = render_resource_monitor_template(
                        ResourceTemplate.MONGODB_CONNECTION_MONITOR.value,
                        pool_status="å¥åº·",
                        current_connections=8,
                        available_connections=12,
                        pending_requests=0,
                        timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
                    )
                    if mongodb_conn_result:
                        send_crawler_status(
                            title=mongodb_conn_result['title'],
                            content=mongodb_conn_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as e:
                    self.logger.warning(f"å‘é€MongoDBè¿æ¥ç›‘æ§å¤±è´¥: {e}")
            
            # éšæœºæ¨¡æ‹Ÿæ€§èƒ½è­¦å‘Šï¼ˆé™ä½é¢‘ç‡ï¼‰
            if random.random() < 0.005:  # 0.5%æ¦‚ç‡
                perf_warning_response = send_template_notification(
                    Template.performance_warning,
                    metric_name='å“åº”æ—¶é—´',
                    current_value='3.5s',
                    threshold='2.0s',
                    task_name='ofweekçˆ¬è™«',
                    channel=ChannelType.DINGTALK
                )
                
                # åŒæ—¶å‘é€MySQLèµ„æºæ³„éœ²å‘Šè­¦ï¼ˆæ¨¡æ‹Ÿï¼‰
                try:
                    mysql_leak_result = render_resource_monitor_template(
                        ResourceTemplate.MYSQL_RESOURCE_LEAK_ALERT.value,
                        current_connections=45,
                        max_connections=50,
                        leak_type="è¿æ¥æ³„éœ²",
                        leak_tag="HIGH_USAGE",
                        discovery_time=time.strftime('%Y-%m-%d %H:%M:%S'),
                        impact_scope="ofweek_spider"
                    )
                    if mysql_leak_result:
                        send_crawler_alert(
                            title=mysql_leak_result['title'],
                            content=mysql_leak_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as e:
                    self.logger.warning(f"å‘é€MySQLèµ„æºæ³„éœ²å‘Šè­¦å¤±è´¥: {e}")
            
            # éšæœºæ¨¡æ‹Ÿç™»å½•çŠ¶æ€ç›‘æ§ï¼ˆé™ä½é¢‘ç‡ï¼‰
            if random.random() < 0.01:  # 1%æ¦‚ç‡
                login_status_response = send_template_notification(
                    Template.login_failed,
                    login_status='æ­£å¸¸' if random.random() > 0.5 else 'å¼‚å¸¸',
                    cookie_status='æœ‰æ•ˆ' if random.random() > 0.3 else 'å¤±æ•ˆ',
                    session_status='æ´»è·ƒ' if random.random() > 0.4 else 'è¿‡æœŸ',
                    error_time=self.get_current_time_str(),
                    channel=ChannelType.DINGTALK
                )
                
                # åŒæ—¶å‘é€Redisèµ„æºæ³„éœ²å‘Šè­¦ï¼ˆæ¨¡æ‹Ÿï¼‰
                try:
                    redis_leak_result = render_resource_monitor_template(
                        ResourceTemplate.REDIS_RESOURCE_LEAK_ALERT.value,
                        current_connections=0,  # Redisä¸é€‚ç”¨æ­¤å­—æ®µ
                        current_memory_mb=2560,
                        leak_trend="æŒç»­å¢é•¿",
                        leak_identifier="HIGH_MEMORY_USAGE",
                        discovery_time=time.strftime('%Y-%m-%d %H:%M:%S'),
                        impact_scope="ç¼“å­˜æœåŠ¡"
                    )
                    if redis_leak_result:
                        send_crawler_alert(
                            title=redis_leak_result['title'],
                            content=redis_leak_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as e:
                    self.logger.warning(f"å‘é€Redisèµ„æºæ³„éœ²å‘Šè­¦å¤±è´¥: {e}")
            
            yield item
            
        except Exception as e:
            self.stats['failed_requests'] += 1
            self.logger.error(f"è§£æè¯¦æƒ…é¡µ {response.url} æ—¶å‡ºé”™: {e}")
            
            # å‘é€è§£æå¤±è´¥é€šçŸ¥ï¼ˆé™ä½é¢‘ç‡ï¼‰
            if self.stats['failed_requests'] % 10 == 1:
                parse_error_response = send_template_notification(
                    Template.parse_failure,
                    parse_success='å¦',
                    data_count='0',
                    error_type=f'{type(e).__name__}: {str(e)}',
                    url=response.url,
                    channel=ChannelType.DINGTALK
                )
                
                # åŒæ—¶å‘é€MongoDBç´¢å¼•ç¼ºå¤±å‘Šè­¦
                try:
                    mongodb_index_result = render_resource_monitor_template(
                        ResourceTemplate.MONGODB_INDEX_MISS_ALERT.value,
                        collection_name="articles",
                        query_condition=f"title: {response.meta.get('title', 'unknown')}",
                        scanned_documents=10000,
                        returned_documents=1,
                        recommended_index="{title: 1}"
                    )
                    if mongodb_index_result:
                        send_crawler_alert(
                            title=mongodb_index_result['title'],
                            content=mongodb_index_result['content'],
                            channel=ChannelType.DINGTALK
                        )
                except Exception as e:
                    self.logger.warning(f"å‘é€MongoDBç´¢å¼•ç¼ºå¤±å‘Šè­¦å¤±è´¥: {e}")
    
    async def closed(self, reason):
        """çˆ¬è™«å…³é—­æ—¶çš„å›è°ƒ - å‘é€æ€»ç»“é€šçŸ¥"""
        # è®¡ç®—è¿è¡Œæ—¶é•¿
        run_duration = self.get_run_duration()
        
        # å‘é€ä»»åŠ¡å®Œæˆæ€»ç»“é€šçŸ¥
        response = send_template_notification(
            Template.task_completion,
            task_name='ofweekçˆ¬è™«',
            success_count=self.stats['successful_items'],
            duration=run_duration,
            channel=ChannelType.DINGTALK
        )
        if not response.success:
            self.logger.warning(f"å‘é€å®Œæˆé€šçŸ¥å¤±è´¥: {response.message}")
        
        # å‘é€æ¯æ—¥æŠ¥å‘Šç»Ÿè®¡
        daily_report_response = send_template_notification(
            Template.daily_report,
            date=self.get_current_date(),
            new_count=self.stats['successful_items'],
            total_count=self.stats['total_requests'],
            success_rate=f"{(self.stats['successful_items']/max(1,self.stats['total_requests'])*100):.2f}",
            channel=ChannelType.DINGTALK
        )
        
        # å‘é€æ€§èƒ½æ€»ç»“ï¼ˆåªæœ‰åœ¨æœ‰å¤±è´¥è¯·æ±‚æ—¶æ‰å‘é€ï¼‰
        if self.stats['failed_requests'] > 0:
            error_summary_response = send_template_notification(
                Template.weekly_report,  # ç”¨ä½œé”™è¯¯æ±‡æ€»
                date=self.get_current_date(),
                new_count=self.stats['failed_requests'],
                total_count=self.stats['total_requests'],
                success_rate=f"{((self.stats['total_requests']-self.stats['failed_requests'])/max(1,self.stats['total_requests'])*100):.2f}",
                period='é”™è¯¯æ±‡æ€»',
                channel=ChannelType.DINGTALK
            )
        
        # å‘é€èµ„æºä½¿ç”¨æƒ…å†µï¼ˆåªåœ¨æœ‰è¶³å¤Ÿæ•°æ®æ—¶æ‰å‘é€ï¼‰
        if self.stats['successful_items'] > 0 or self.stats['failed_requests'] > 0:
            resource_response = send_template_notification(
                Template.resource_monitor,
                memory_usage='75',
                cpu_usage='60',
                disk_usage='40',
                active_connections='56',
                channel=ChannelType.DINGTALK
            )
            
            # å‘é€æœ€ç»ˆçš„èµ„æºç›‘æ§æ€»ç»“
            try:
                final_mysql_monitor = render_resource_monitor_template(
                    ResourceTemplate.MYSQL_CONNECTION_POOL_MONITOR.value,
                    pool_status="æ­£å¸¸" if self.stats['failed_requests'] < 10 else "å‹åŠ›",
                    active_connections=min(50, 10 + self.stats['successful_items'] // 10),
                    idle_connections=max(1, 15 - self.stats['failed_requests'] // 5),
                    max_connections=50,
                    waiting_connections=0,
                    timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
                )
                if final_mysql_monitor:
                    send_crawler_status(
                        title=final_mysql_monitor['title'],
                        content=final_mysql_monitor['content'],
                        channel=ChannelType.DINGTALK
                    )
            except Exception as e:
                self.logger.warning(f"å‘é€æœ€ç»ˆMySQLç›‘æ§å¤±è´¥: {e}")
            
            try:
                final_redis_monitor = render_resource_monitor_template(
                    ResourceTemplate.REDIS_MEMORY_MONITOR.value,
                    used_memory=f"{2.0 + self.stats['successful_items']*0.01:.1f}GB",
                    max_memory="4GB",
                    memory_usage_percent=min(90, (2.0 + self.stats['successful_items']*0.01)/4.0*100),
                    memory_fragmentation_ratio=round(1.0 + random.random()*0.5, 2),
                    hit_rate=max(80, 98.5 - self.stats['failed_requests']*0.1),
                    timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
                )
                if final_redis_monitor:
                    send_crawler_status(
                        title=final_redis_monitor['title'],
                        content=final_redis_monitor['content'],
                        channel=ChannelType.DINGTALK
                    )
            except Exception as e:
                self.logger.warning(f"å‘é€æœ€ç»ˆRedisç›‘æ§å¤±è´¥: {e}")
        
        # å‘é€å®‰å…¨å‘Šè­¦ï¼ˆåªæœ‰åœ¨æœ‰é”™è¯¯æ—¶æ‰å‘é€ï¼‰
        if self.stats['failed_requests'] > 0:
            security_response = send_template_notification(
                Template.security_alert,
                security_alert='çˆ¬è™«è¿è¡Œå¼‚å¸¸',
                auth_status='æ­£å¸¸',
                access_denied='å¦',
                error_time=self.get_current_time_str(),
                channel=ChannelType.DINGTALK
            )
            
            # å‘é€æœ€ç»ˆçš„èµ„æºæ³„éœ²ç›‘æ§
            try:
                final_leak_monitor = render_resource_monitor_template(
                    ResourceTemplate.GENERAL_RESOURCE_LEAK_ALERT.value,
                    resource_type="è¿æ¥æ•°",
                    leak_details=f"æ€»è¯·æ±‚æ•°: {self.stats['total_requests']}, å¤±è´¥è¯·æ±‚æ•°: {self.stats['failed_requests']}",
                    growth_trend="ç¨³å®š" if self.stats['failed_requests'] < 5 else "å¢é•¿",
                    severity_level="ä½" if self.stats['failed_requests'] < 5 else "ä¸­ç­‰",
                    discovery_time=time.strftime('%Y-%m-%d %H:%M:%S'),
                    affected_service="ofweek_spider"
                )
                if final_leak_monitor:
                    send_crawler_alert(
                        title=final_leak_monitor['title'],
                        content=final_leak_monitor['content'],
                        channel=ChannelType.DINGTALK
                    )
            except Exception as e:
                self.logger.warning(f"å‘é€æœ€ç»ˆèµ„æºæ³„éœ²ç›‘æ§å¤±è´¥: {e}")
        
        self.logger.info("çˆ¬è™«å®Œæˆæ€»ç»“é€šçŸ¥å·²å‘é€")

    def get_current_date(self):
        """è·å–å½“å‰æ—¥æœŸ"""
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d')
    
    def get_current_time(self):
        """è·å–å½“å‰æ—¶é—´"""
        from datetime import datetime
        return datetime.now()
    
    def get_run_duration(self):
        """è®¡ç®—è¿è¡Œæ—¶é•¿"""
        if not self.stats['start_time']:
            return "æœªçŸ¥"
        
        from datetime import datetime
        duration = datetime.now() - self.stats['start_time']
        hours, remainder = divmod(duration.seconds, 3600)
        minutes, seconds = divmod(remainder, 60)
        return f"{hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’"
    
    def get_current_time_str(self):
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        return self.get_current_time().strftime('%Y-%m-%d %H:%M:%S')
    
    def handle_error(self, failure):
        """å¤„ç†è¯·æ±‚é”™è¯¯"""
        self.logger.error(f"è¯·æ±‚å¤±è´¥: {failure}")
        self.stats['failed_requests'] += 1


# ä½¿ç”¨ç¤ºä¾‹
def run_spider_with_notifications():
    """è¿è¡Œå¸¦é€šçŸ¥çš„çˆ¬è™«ç¤ºä¾‹"""
    print("ğŸš€ å¯åŠ¨é›†æˆé€šçŸ¥åŠŸèƒ½çš„ ofweek çˆ¬è™«...")
    
    # è¿™é‡Œåº”è¯¥æ˜¯å®é™…çš„çˆ¬è™«è¿è¡Œä»£ç 
    # ç”±äºè¿™æ˜¯ç¤ºä¾‹ï¼Œæˆ‘ä»¬åªæ¼”ç¤ºé€šçŸ¥åŠŸèƒ½
    
    async def demo():
        # æ¨¡æ‹Ÿçˆ¬è™«è¿è¡Œè¿‡ç¨‹ä¸­çš„é€šçŸ¥
        await send_crawler_status(
            title="ã€ç¤ºä¾‹ã€‘çˆ¬è™«é€šçŸ¥åŠŸèƒ½æ¼”ç¤º",
            content="è¿™æ˜¯æ¼”ç¤ºå¦‚ä½•åœ¨çˆ¬è™«ä¸­ä½¿ç”¨é€šçŸ¥åŠŸèƒ½çš„ç¤ºä¾‹",
            channel=ChannelType.DINGTALK
        )
    
    asyncio.run(demo())
    print("âœ… æ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    run_spider_with_notifications()
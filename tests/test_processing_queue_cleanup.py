#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¤„ç†é˜Ÿåˆ—åœ¨çˆ¬è™«æ­£å¸¸ç»“æŸæ—¶çš„æ¸…ç†è¡Œä¸º
æ¨¡æ‹Ÿå®é™…çˆ¬è™«åœºæ™¯ï¼ŒéªŒè¯CLEANUP_REDIS_DATAå‚æ•°çš„è¡Œä¸º
"""
import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from crawlo.queue.redis_priority_queue import RedisPriorityQueue
from crawlo.network.request import Request


async def test_processing_queue_cleanup():
    """æµ‹è¯•å¤„ç†é˜Ÿåˆ—åœ¨çˆ¬è™«æ­£å¸¸ç»“æŸæ—¶çš„æ¸…ç†è¡Œä¸º"""
    print("å¼€å§‹æµ‹è¯•å¤„ç†é˜Ÿåˆ—åœ¨çˆ¬è™«æ­£å¸¸ç»“æŸæ—¶çš„æ¸…ç†è¡Œä¸º...")
    print("=" * 60)
    
    queue = None
    redis_conn = None
    try:
        # åˆ›å»ºRedisé˜Ÿåˆ—å®ä¾‹ï¼Œè®¾ç½®cleanup_redis_data=Falseä»¥ä¿ç•™æ•°æ®
        queue = RedisPriorityQueue(
            redis_url="redis://127.0.0.1:6379/15",  # ä½¿ç”¨æµ‹è¯•æ•°æ®åº“
            queue_name="test:queue:cleanup",
            module_name="test_cleanup",
            timeout=300,  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º300ç§’
            cleanup_redis_data=False  # ä¸è‡ªåŠ¨æ¸…ç†æ•°æ®ä»¥æ”¯æŒæ–­ç‚¹ç»­çˆ¬
        )
        
        # è¿æ¥Redis
        await queue.connect()
        print("âœ… Redisè¿æ¥æˆåŠŸ")
        
        # ä¿å­˜Redisè¿æ¥å¼•ç”¨ç”¨äºåç»­æ£€æŸ¥
        redis_conn = queue._redis
        
        # ç¡®ä¿Redisè¿æ¥å­˜åœ¨
        if not redis_conn:
            print("âŒ Redisè¿æ¥å¤±è´¥")
            return False
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§æ•°æ®
        await redis_conn.delete(
            queue.queue_name,
            f"{queue.queue_name}:data",
            queue.processing_queue,
            f"{queue.processing_queue}:data"
        )
        print("âœ… æ—§æ•°æ®æ¸…ç†å®Œæˆ")
        
        # æ·»åŠ å¤šä¸ªæµ‹è¯•è¯·æ±‚
        test_requests = [
            Request(url="https://example.com/test1", priority=0),
            Request(url="https://example.com/test2", priority=0),
            Request(url="https://example.com/test3", priority=0),
        ]
        
        print(f"\n--- æ·»åŠ  {len(test_requests)} ä¸ªæµ‹è¯•è¯·æ±‚ ---")
        for i, request in enumerate(test_requests):
            success = await queue.put(request, priority=0)
            if success:
                print(f"âœ… è¯·æ±‚{i+1}å·²æ·»åŠ åˆ°ä¸»é˜Ÿåˆ—: {request.url}")
            else:
                print(f"âŒ è¯·æ±‚{i+1}æ·»åŠ å¤±è´¥")
                return False
        
        # æ£€æŸ¥åˆå§‹çŠ¶æ€
        main_queue_size = await redis_conn.zcard(queue.queue_name)
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\nåˆå§‹çŠ¶æ€:")
        print(f"  ä¸»é˜Ÿåˆ—å¤§å°: {main_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # ä»ä¸»é˜Ÿåˆ—è·å–æ‰€æœ‰ä»»åŠ¡ï¼ˆä¼šè‡ªåŠ¨ç§»åŠ¨åˆ°å¤„ç†é˜Ÿåˆ—ï¼‰
        print(f"\n--- ä»ä¸»é˜Ÿåˆ—è·å–ä»»åŠ¡ ---")
        processed_requests = []
        for i in range(len(test_requests)):
            request = await queue.get(timeout=1.0)
            if request:
                print(f"âœ… ä»»åŠ¡{i+1}å·²ä»ä¸»é˜Ÿåˆ—å–å‡ºå¹¶ç§»åŠ¨åˆ°å¤„ç†é˜Ÿåˆ—: {request.url}")
                processed_requests.append(request)
            else:
                print(f"âŒ æ— æ³•è·å–ä»»åŠ¡{i+1}")
                return False
        
        # æ£€æŸ¥è·å–ä»»åŠ¡åçš„çŠ¶æ€
        main_queue_size = await redis_conn.zcard(queue.queue_name)
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\nè·å–ä»»åŠ¡åçŠ¶æ€:")
        print(f"  ä¸»é˜Ÿåˆ—å¤§å°: {main_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # éƒ¨åˆ†è°ƒç”¨ackæ–¹æ³•ç¡®è®¤ä»»åŠ¡å®Œæˆï¼ˆæ¨¡æ‹Ÿéƒ¨åˆ†ä»»åŠ¡å®Œæˆï¼‰
        print(f"\n--- è°ƒç”¨ackæ–¹æ³•ç¡®è®¤éƒ¨åˆ†ä»»åŠ¡å®Œæˆ ---")
        for i, request in enumerate(processed_requests[:-1]):  # ç¡®è®¤å‰ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
            await queue.ack(request)
            print(f"âœ… ä»»åŠ¡{i+1}å·²å®Œæˆå¹¶ä»å¤„ç†é˜Ÿåˆ—ç§»é™¤: {request.url}")
        
        # æ£€æŸ¥éƒ¨åˆ†ackåçš„çŠ¶æ€
        main_queue_size = await redis_conn.zcard(queue.queue_name)
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\néƒ¨åˆ†ackåçŠ¶æ€:")
        print(f"  ä¸»é˜Ÿåˆ—å¤§å°: {main_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # æ¨¡æ‹Ÿè°ƒç”¨closeæ–¹æ³•ï¼ˆæ¨¡æ‹Ÿçˆ¬è™«æ­£å¸¸ç»“æŸï¼‰
        print(f"\n--- è°ƒç”¨closeæ–¹æ³•ï¼ˆæ¨¡æ‹Ÿçˆ¬è™«æ­£å¸¸ç»“æŸï¼‰ ---")
        # ç”±äºcleanup_redis_data=Falseï¼Œcloseæ–¹æ³•åº”è¯¥ä¿ç•™å¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®
        await queue.close()
        print("âœ… closeæ–¹æ³•è°ƒç”¨å®Œæˆ")
        
        # é‡æ–°è¿æ¥Redisä»¥æ£€æŸ¥çŠ¶æ€
        await queue.connect()
        redis_conn = queue._redis
        
        # æ£€æŸ¥closeåçš„çŠ¶æ€
        main_queue_size = await redis_conn.zcard(queue.queue_name)
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\ncloseåçŠ¶æ€:")
        print(f"  ä¸»é˜Ÿåˆ—å¤§å°: {main_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # éªŒè¯ç»“æœ
        if main_queue_size == 0 and processing_queue_size > 0 and processing_data_size > 0:
            print("\nâœ… å¤„ç†é˜Ÿåˆ—æ•°æ®è¢«æ­£ç¡®ä¿ç•™ï¼Œæ”¯æŒæ–­ç‚¹ç»­çˆ¬")
            print(f"   æœªå®Œæˆçš„ä»»åŠ¡æ•°é‡: {processing_queue_size}")
            return True
        elif main_queue_size == 0 and processing_queue_size == 0 and processing_data_size == 0:
            print("\nâŒ å¤„ç†é˜Ÿåˆ—æ•°æ®è¢«æ„å¤–æ¸…ç†")
            return False
        else:
            print(f"\nâ“ æ„å¤–çŠ¶æ€: ä¸»é˜Ÿåˆ—={main_queue_size}, å¤„ç†é˜Ÿåˆ—={processing_queue_size}, æ•°æ®={processing_data_size}")
            return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        if redis_conn:
            await redis_conn.delete(
                queue.queue_name,
                f"{queue.queue_name}:data",
                queue.processing_queue,
                f"{queue.processing_queue}:data"
            )


async def test_processing_queue_cleanup_with_auto_cleanup():
    """æµ‹è¯•å¤„ç†é˜Ÿåˆ—åœ¨è‡ªåŠ¨æ¸…ç†æ¨¡å¼ä¸‹çš„è¡Œä¸º"""
    print("\n\nå¼€å§‹æµ‹è¯•å¤„ç†é˜Ÿåˆ—åœ¨è‡ªåŠ¨æ¸…ç†æ¨¡å¼ä¸‹çš„è¡Œä¸º...")
    print("=" * 60)
    
    queue = None
    redis_conn = None
    try:
        # åˆ›å»ºRedisé˜Ÿåˆ—å®ä¾‹ï¼Œè®¾ç½®cleanup_redis_data=Trueä»¥è‡ªåŠ¨æ¸…ç†æ•°æ®
        queue = RedisPriorityQueue(
            redis_url="redis://127.0.0.1:6379/15",  # ä½¿ç”¨æµ‹è¯•æ•°æ®åº“
            queue_name="test:queue:auto_cleanup",
            module_name="test_auto_cleanup",
            timeout=300,  # è®¾ç½®è¶…æ—¶æ—¶é—´ä¸º300ç§’
            cleanup_redis_data=True  # è‡ªåŠ¨æ¸…ç†æ•°æ®
        )
        
        # è¿æ¥Redis
        await queue.connect()
        print("âœ… Redisè¿æ¥æˆåŠŸ")
        
        # ä¿å­˜Redisè¿æ¥å¼•ç”¨ç”¨äºåç»­æ£€æŸ¥
        redis_conn = queue._redis
        
        # ç¡®ä¿Redisè¿æ¥å­˜åœ¨
        if not redis_conn:
            print("âŒ Redisè¿æ¥å¤±è´¥")
            return False
        
        # æ¸…ç†å¯èƒ½å­˜åœ¨çš„æ—§æ•°æ®
        await redis_conn.delete(
            queue.queue_name,
            f"{queue.queue_name}:data",
            queue.processing_queue,
            f"{queue.processing_queue}:data"
        )
        print("âœ… æ—§æ•°æ®æ¸…ç†å®Œæˆ")
        
        # æ·»åŠ æµ‹è¯•è¯·æ±‚
        test_requests = [
            Request(url="https://example.com/test1", priority=0),
            Request(url="https://example.com/test2", priority=0),
        ]
        
        print(f"\n--- æ·»åŠ  {len(test_requests)} ä¸ªæµ‹è¯•è¯·æ±‚ ---")
        for i, request in enumerate(test_requests):
            success = await queue.put(request, priority=0)
            if success:
                print(f"âœ… è¯·æ±‚{i+1}å·²æ·»åŠ åˆ°ä¸»é˜Ÿåˆ—: {request.url}")
            else:
                print(f"âŒ è¯·æ±‚{i+1}æ·»åŠ å¤±è´¥")
                return False
        
        # ä»ä¸»é˜Ÿåˆ—è·å–æ‰€æœ‰ä»»åŠ¡
        print(f"\n--- ä»ä¸»é˜Ÿåˆ—è·å–ä»»åŠ¡ ---")
        processed_requests = []
        for i in range(len(test_requests)):
            request = await queue.get(timeout=1.0)
            if request:
                print(f"âœ… ä»»åŠ¡{i+1}å·²ä»ä¸»é˜Ÿåˆ—å–å‡ºå¹¶ç§»åŠ¨åˆ°å¤„ç†é˜Ÿåˆ—: {request.url}")
                processed_requests.append(request)
            else:
                print(f"âŒ æ— æ³•è·å–ä»»åŠ¡{i+1}")
                return False
        
        # éƒ¨åˆ†è°ƒç”¨ackæ–¹æ³•ç¡®è®¤ä»»åŠ¡å®Œæˆ
        print(f"\n--- è°ƒç”¨ackæ–¹æ³•ç¡®è®¤éƒ¨åˆ†ä»»åŠ¡å®Œæˆ ---")
        for i, request in enumerate(processed_requests[:-1]):  # ç¡®è®¤ç¬¬ä¸€ä¸ªä»»åŠ¡å®Œæˆ
            await queue.ack(request)
            print(f"âœ… ä»»åŠ¡{i+1}å·²å®Œæˆå¹¶ä»å¤„ç†é˜Ÿåˆ—ç§»é™¤: {request.url}")
        
        # æ£€æŸ¥çŠ¶æ€
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\nackåçŠ¶æ€:")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # æ¨¡æ‹Ÿè°ƒç”¨closeæ–¹æ³•ï¼ˆæ¨¡æ‹Ÿçˆ¬è™«æ­£å¸¸ç»“æŸï¼‰
        print(f"\n--- è°ƒç”¨closeæ–¹æ³•ï¼ˆæ¨¡æ‹Ÿçˆ¬è™«æ­£å¸¸ç»“æŸï¼‰ ---")
        # ç”±äºcleanup_redis_data=Trueï¼Œcloseæ–¹æ³•åº”è¯¥æ¸…ç†å¤„ç†é˜Ÿåˆ—ä¸­çš„æ•°æ®
        await queue.close()
        print("âœ… closeæ–¹æ³•è°ƒç”¨å®Œæˆ")
        
        # é‡æ–°è¿æ¥Redisä»¥æ£€æŸ¥çŠ¶æ€
        await queue.connect()
        redis_conn = queue._redis
        
        # æ£€æŸ¥closeåçš„çŠ¶æ€
        main_queue_size = await redis_conn.zcard(queue.queue_name)
        processing_queue_size = await redis_conn.zcard(queue.processing_queue)
        processing_data_size = await redis_conn.hlen(f"{queue.processing_queue}:data")
        
        print(f"\ncloseåçŠ¶æ€:")
        print(f"  ä¸»é˜Ÿåˆ—å¤§å°: {main_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—å¤§å°: {processing_queue_size}")
        print(f"  å¤„ç†é˜Ÿåˆ—æ•°æ®å¤§å°: {processing_data_size}")
        
        # éªŒè¯ç»“æœ
        if main_queue_size == 0 and processing_queue_size == 0 and processing_data_size == 0:
            print("\nâœ… å¤„ç†é˜Ÿåˆ—æ•°æ®è¢«æ­£ç¡®æ¸…ç†")
            return True
        else:
            print(f"\nâŒ å¤„ç†é˜Ÿåˆ—æ•°æ®æœªè¢«æ­£ç¡®æ¸…ç†: ä¸»é˜Ÿåˆ—={main_queue_size}, å¤„ç†é˜Ÿåˆ—={processing_queue_size}, æ•°æ®={processing_data_size}")
            return False
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        # æ¸…ç†æµ‹è¯•æ•°æ®
        if redis_conn:
            await redis_conn.delete(
                queue.queue_name,
                f"{queue.queue_name}:data",
                queue.processing_queue,
                f"{queue.processing_queue}:data"
            )


if __name__ == "__main__":
    print("æµ‹è¯•å¤„ç†é˜Ÿåˆ—æ¸…ç†è¡Œä¸º")
    print("=" * 60)
    
    # æµ‹è¯•ä¿ç•™æ•°æ®æ¨¡å¼
    result1 = asyncio.run(test_processing_queue_cleanup())
    
    # æµ‹è¯•è‡ªåŠ¨æ¸…ç†æ¨¡å¼
    result2 = asyncio.run(test_processing_queue_cleanup_with_auto_cleanup())
    
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"  ä¿ç•™æ•°æ®æ¨¡å¼æµ‹è¯•: {'é€šè¿‡' if result1 else 'å¤±è´¥'}")
    print(f"  è‡ªåŠ¨æ¸…ç†æ¨¡å¼æµ‹è¯•: {'é€šè¿‡' if result2 else 'å¤±è´¥'}")
    
    if result1 and result2:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡")
    else:
        print("\nğŸ’¥ éƒ¨åˆ†æµ‹è¯•å¤±è´¥")